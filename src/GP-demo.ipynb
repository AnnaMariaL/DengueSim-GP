{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33edc719",
   "metadata": {},
   "source": [
    "\n",
    "# Gaussian Process Emulator Demonstration\n",
    "\n",
    "This notebook demonstrates handling **Gaussian Process (GP)** emulators used in the work *Gaussian Process emulation for exploring complex infectious disease models*, which is currently available as a [preprint](https://www.medrxiv.org/content/10.1101/2024.11.28.24318136v2).\n",
    "\n",
    "It walks through the following key steps:\n",
    "1. Set up: Imports, Data Paths, and Parameter Space\n",
    "2. Loading the Gaussian Process emulator\n",
    "3. Evaluating GP performance\n",
    "4. Sensitivity Analysis with the GP\n",
    "5. Predictions with the GP\n",
    "6. Sampling additional points based on GP predictions\n",
    "\n",
    "For more information on GPs, please refer to:\n",
    "- [GPyTorch Tutorials](https://gpytorch.ai)\n",
    "- [Rasmussen & Williams (2006): *Gaussian Processes for Machine Learning*](http://www.gaussianprocess.org/gpml/)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up: Imports, Data Paths, and Parameter Space\n",
    "\n",
    "In this section, we import the necessary libraries and define the key configuration elements used throughout the Gaussian Process emulation workflow.\n",
    "\n",
    "* **`SIR_gp`**: This module contains the main Gaussian Process (GP) class implementation used for training and prediction.\n",
    "* **`itertools.product`** and **`IPython.display.HTML`**: Utilities for data handling and HTML-based display of results within the notebook.\n",
    "* **`emukit`**: Provides tools for **design of experiments** — here, we use its `ParameterSpace` and `LatinDesign` classes to perform **Latin Hypercube Sampling (LHS)**, ensuring that training data cover the input domain evenly.\n",
    "* **`warnings.filterwarnings(\"ignore\")`**: Suppresses non-critical warnings for cleaner notebook output.\n",
    "\n",
    "Next, we define paths to:\n",
    "\n",
    "* The **training data** (`PATH_TRAIN`)\n",
    "* The **test data** (`PATH_TEST`)\n",
    "* A **pretrained GP model snapshot** (`PATH_MODEL`)\n",
    "\n",
    "Please check the **README** in the `../data/GP/data` directory for dataset details. \n",
    "\n",
    "The variable **`MODEL_TYPE`** indicates which epidemiological outcome the GP emulator models — for example:\n",
    "\n",
    "* `\"maxIncidence\"`: maximum incidence\n",
    "* `\"establishment\"`: outbreak probability\n",
    "* `\"duration\"`: epidemic duration (log-10 transformed)\n",
    "\n",
    "Finally, we define the **parameter space** using `emukit`’s `ParameterSpace`.\n",
    "Each `ContinuousParameter` specifies a model parameter and its range.\n",
    "\n",
    "The table below maps the variable names used in the code to their corresponding names and explanations in the manuscript.\n",
    "\n",
    "\n",
    "| **Code Variable**  | **Manuscript Name**      | **Description**                                                                                                                    | **Range**    |\n",
    "| ------------------ | ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------- | ------------ |\n",
    "| `alphaRest`        | **Average infectivity**  | Average infection probability across a year, removing the effect of seasonality.                                                   | [0, 0.03]    |\n",
    "| `alphaAmp`         | **Seasonality strength** | Scaling factor (0–1) controlling the magnitude of seasonal variation in infection probability.                                     | [0, 1]       |\n",
    "| `alphaShift`       | **First case timing**    | Timing of the first case relative to the seasonal peak in infection probability.                                                   | [0, 1]       |\n",
    "| `infTicksCount`    | **Infectious period**    | Average number of days an individual remains infectious; actual durations vary probabilistically around this value.                | [4, 6]       |\n",
    "| `avgVisitsCount`   | **Average mobility**     | Average number of visits a person makes to locations per day (in addition to their home).                                          | [1, 5]       |\n",
    "| `pVisits`          | **Mobility skewness**    | Success probability in the negative binomial distribution determining daily visit counts — lower values yield greater variability. | [0.05, 0.95] |\n",
    "| `propSocialVisits` | **Social structure**     | Probability that a visit occurs within an individual’s family cluster.                                                             | [0, 1]       |\n",
    "| `locPerSGCount`    | **Family cluster size**  | Average number of locations per family cluster; actual sizes are probabilistically rounded around this value.                      | [1, 20]      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SIR_gp import * #class implementation of the GP\n",
    "from itertools import product\n",
    "from IPython.display import HTML\n",
    "from emukit.core import ParameterSpace, ContinuousParameter #emukit for LHS\n",
    "from emukit.core.initial_designs.latin_design import LatinDesign #emukit for LHS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PATH_TRAIN = \"../data/GP/data/sim-training-maxIncidence-round15.txt\" #training data \n",
    "PATH_TEST = \"../data/GP/data/DD-AML-test-LHS-10000-condSim-logDuration.txt\" #test data \n",
    "PATH_MODEL = \"../data/GP/model/maxIncidence-round15-snap3.pth\" #trained GP model snapshot \n",
    "MODEL_TYPE = \"maxIncidence\" #defines GP type: imax = maxIncidence, outbreak probability = establishment, duration = duration \n",
    "\n",
    "PARAM_RANGES = ParameterSpace([\n",
    "    ContinuousParameter(\"alphaRest\",0 , 0.03),\n",
    "    ContinuousParameter(\"alphaAmp\", 0, 1),\n",
    "    ContinuousParameter(\"alphaShift\", 0, 1),\n",
    "    ContinuousParameter(\"infTicksCount\", 4, 6),\n",
    "    ContinuousParameter(\"avgVisitsCount\", 1, 5),\n",
    "    ContinuousParameter(\"pVisits\", 0.05, 0.95),\n",
    "    ContinuousParameter(\"propSocialVisits\", 0, 1),\n",
    "    ContinuousParameter(\"locPerSGCount\", 1, 20),\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Gaussian Process emulator\n",
    "\n",
    "In this step, we initialize and load a pre-trained Gaussian Process (GP) emulator based on the `SIR_GP` class defined in `SIR_gp.py`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Loss: -1.7712738513946533\n"
     ]
    }
   ],
   "source": [
    "myGP = SIR_GP(training_data=PATH_TRAIN, model_type=MODEL_TYPE)\n",
    "myGP.load(filename=PATH_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* The first line creates an instance of the `SIR_GP` class.\n",
    "\n",
    "  * `training_data=PATH_TRAIN` points to the file containing the training dataset used to fit the GP.\n",
    "  * `model_type=MODEL_TYPE` specifies which epidemiological outcome the emulator predicts (e.g., *maximum incidence*, *outbreak probability*, or *epidemic duration*).\n",
    "\n",
    "* The second line loads a pre-trained model snapshot (`.pth` file) from disk.\n",
    "  This includes the learned kernel hyperparameters obtained during training.\n",
    "\n",
    "Internally, `SIR_GP` automatically detects whether a GPU is available and places the model on the appropriate device.\n",
    "\n",
    "This ensures the emulator runs efficiently on GPU-equipped systems but remains fully functional on CPU-only machines.\n",
    "\n",
    "Once loaded, `myGP` is ready to make predictions for new parameter combinations sampled from the defined input space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Training the GP model\n",
    "\n",
    "The code below demonstrates how to train the GP model for **one iteration** .  \n",
    "\n",
    "The `train` method updates the GP model using the training data we provided when creating `myGP` and returns the loss after training.\n",
    "\n",
    "`num_iterations=1` means the model will go through the training data only **once**. Normally, you would use many iterations (hundreds or thousands) to get a well-trained model.\n",
    "\n",
    "**Note:** Training for more iterations can take a long time, especially if a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7759909629821777"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.train(num_iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating Gaussian Process performance\n",
    "\n",
    "* `get_rmse()` evaluates how well the GP model predicts unseen data.\n",
    "* `test_data` is a CSV file containing inputs and true outputs for the test set.\n",
    "* RMSE (Root Mean Square Error) measures the average difference between predicted and actual values:\n",
    "  * Smaller RMSE → better predictions.\n",
    "* This is a common way to check the **accuracy** of a surrogate model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042115769745832025"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.get_rmse(test_data=PATH_TEST)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sensitivity analysis with the GP\n",
    "\n",
    "### 4.1. Sensitivity analysis across whole input domain \n",
    "`myGP.param_ranges` shows the **range of values** each input parameter can take. These define the input domain for the model.\n",
    "   Example: `alphaRest` ranges from 0 to 0.03, `alphaAmp` from 0 to 1, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphaRest': (0, 0.03),\n",
       " 'alphaAmp': (0, 1),\n",
       " 'alphaShift': (0, 1),\n",
       " 'infTicksCount': (4, 6),\n",
       " 'avgVisitsCount': (1, 5),\n",
       " 'pVisits': (0.05, 0.95),\n",
       " 'propSocialVisits': (0, 1),\n",
       " 'locPerSGCount': (1, 20)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.param_ranges # View the input parameter ranges (model domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sensitivity_analysis()` performs a **Sobol sensitivity analysis**, which tells us how sensitive the model output is to each input parameter.\n",
    "\n",
    "- `pow2sampleSize=10` means the base number of Sobol samples is:  \n",
    "\n",
    "$$\n",
    "n = 2^{10} = 1024\n",
    "$$\n",
    "\n",
    "- The total number of points evaluated is calculated using the formula:  \n",
    "\n",
    "$$\n",
    "N_\\text{total} = n \\times (2d + 2)\n",
    "$$\n",
    "\n",
    "where $d$ is the number of input parameters.\n",
    "\n",
    "- In our case, $d = 8$, so:\n",
    "\n",
    "$$\n",
    "N_\\text{total} = 1024 \\times (2 \\cdot 8 + 2) = 1024 \\times 18 = 18432\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points to be evaluated: 18432\n",
      "Fished predictions. Starting sensitivity analysis.\n",
      "                        ST   ST_conf\n",
      "alphaRest         0.573244  0.048126\n",
      "alphaAmp          0.037860  0.005755\n",
      "alphaShift        0.129500  0.018578\n",
      "infTicksCount     0.017824  0.001582\n",
      "avgVisitsCount    0.296127  0.030926\n",
      "pVisits           0.001423  0.000143\n",
      "propSocialVisits  0.045998  0.008509\n",
      "locPerSGCount     0.003858  0.001101\n",
      "                        S1   S1_conf\n",
      "alphaRest         0.547259  0.062607\n",
      "alphaAmp          0.009152  0.014850\n",
      "alphaShift        0.080566  0.025421\n",
      "infTicksCount     0.015681  0.013017\n",
      "avgVisitsCount    0.272837  0.050451\n",
      "pVisits           0.000877  0.003000\n",
      "propSocialVisits  0.025461  0.015755\n",
      "locPerSGCount     0.001176  0.004889\n",
      "                                          S2   S2_conf\n",
      "(alphaRest, alphaAmp)              -0.021582  0.093106\n",
      "(alphaRest, alphaShift)            -0.015278  0.096897\n",
      "(alphaRest, infTicksCount)         -0.018158  0.090487\n",
      "(alphaRest, avgVisitsCount)        -0.006596  0.100111\n",
      "(alphaRest, pVisits)               -0.018965  0.091024\n",
      "(alphaRest, propSocialVisits)      -0.013543  0.090223\n",
      "(alphaRest, locPerSGCount)         -0.021073  0.089701\n",
      "(alphaAmp, alphaShift)              0.005499  0.020987\n",
      "(alphaAmp, infTicksCount)          -0.018989  0.021054\n",
      "(alphaAmp, avgVisitsCount)         -0.023871  0.021458\n",
      "(alphaAmp, pVisits)                -0.017814  0.020627\n",
      "(alphaAmp, propSocialVisits)       -0.014250  0.020662\n",
      "(alphaAmp, locPerSGCount)          -0.017258  0.020916\n",
      "(alphaShift, infTicksCount)        -0.006091  0.038768\n",
      "(alphaShift, avgVisitsCount)       -0.010006  0.039124\n",
      "(alphaShift, pVisits)              -0.006402  0.037812\n",
      "(alphaShift, propSocialVisits)     -0.007064  0.038896\n",
      "(alphaShift, locPerSGCount)        -0.006511  0.038220\n",
      "(infTicksCount, avgVisitsCount)     0.001247  0.019769\n",
      "(infTicksCount, pVisits)           -0.000268  0.016900\n",
      "(infTicksCount, propSocialVisits)  -0.001065  0.017290\n",
      "(infTicksCount, locPerSGCount)     -0.000140  0.016758\n",
      "(avgVisitsCount, pVisits)          -0.007672  0.064325\n",
      "(avgVisitsCount, propSocialVisits) -0.002187  0.065746\n",
      "(avgVisitsCount, locPerSGCount)    -0.010057  0.064204\n",
      "(pVisits, propSocialVisits)         0.000412  0.003946\n",
      "(pVisits, locPerSGCount)            0.000331  0.004041\n",
      "(propSocialVisits, locPerSGCount)   0.012530  0.021286\n"
     ]
    }
   ],
   "source": [
    "# Perform a Sobol sensitivity analysis\n",
    "my_sa = myGP.sensitivity_analysis(\n",
    "    pow2sampleSize=10,          # n = 2^10 \n",
    "    param_ranges=myGP.param_ranges,  # Use the defined input ranges\n",
    "    verbose=True                # Print progress and results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function `sensitivity_analysis()` returns **three DataFrames**:\n",
    "\n",
    "1. **Total Effects (ST, ST_conf)**\n",
    "\n",
    "   * `ST` = total sensitivity index for each parameter, including interactions.\n",
    "   * `ST_conf` = confidence interval for `ST`.\n",
    "\n",
    "2. **First-Order Effects (S1, S1_conf)**\n",
    "\n",
    "   * `S1` = contribution to output variance from the parameter **alone**.\n",
    "   * `S1_conf` = confidence interval for `S1`.\n",
    "\n",
    "3. **Second-Order Effects (S2, S2_conf)**\n",
    "\n",
    "   * `S2` = contribution to variance from **interactions between pairs of parameters**.\n",
    "   * `S2_conf` = confidence interval for `S2`.\n",
    "\n",
    "**Key takeaways:**\n",
    "\n",
    "* High `ST`: parameter strongly influences the output.\n",
    "* Low `S1` but high `ST`: parameter important mostly through interactions.\n",
    "* `S2` highlights significant pairwise interactions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Sensitivity analysis over a conditional parameter subdomain \n",
    "\n",
    "Sometimes, we are interested in how the model behaves in constrained scenarios, rather than across the full range of input values.  \n",
    "For example, we might want to study the effects of varying some parameters while keeping others fixed (here: `alphaRest`, `avgVisitsCount`) at typical or average values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points to be evaluated: 18432\n",
      "Fished predictions. Starting sensitivity analysis.\n",
      "                            ST       ST_conf\n",
      "alphaRest         4.162834e-11  5.725125e-12\n",
      "alphaAmp          1.565111e-01  2.165385e-02\n",
      "alphaShift        6.831600e-01  7.663662e-02\n",
      "infTicksCount     8.675130e-02  8.977722e-03\n",
      "avgVisitsCount    1.758958e-11  2.273427e-12\n",
      "pVisits           6.316238e-03  6.522523e-04\n",
      "propSocialVisits  2.067304e-01  4.021282e-02\n",
      "locPerSGCount     1.730275e-02  3.721598e-03\n",
      "                            S1       S1_conf\n",
      "alphaRest        -3.551905e-08  5.796783e-07\n",
      "alphaAmp         -5.781783e-03  3.837352e-02\n",
      "alphaShift        5.089210e-01  7.524991e-02\n",
      "infTicksCount     8.592577e-02  3.221632e-02\n",
      "avgVisitsCount   -2.148522e-07  3.660348e-07\n",
      "pVisits           7.365714e-03  6.379119e-03\n",
      "propSocialVisits  1.880176e-01  5.359591e-02\n",
      "locPerSGCount     5.115693e-03  1.051988e-02\n",
      "                                              S2       S2_conf\n",
      "(alphaRest, alphaAmp)              -1.731307e-07  7.250833e-07\n",
      "(alphaRest, alphaShift)            -3.003700e-07  8.282559e-07\n",
      "(alphaRest, infTicksCount)          8.269706e-08  7.226700e-07\n",
      "(alphaRest, avgVisitsCount)        -5.216020e-08  7.289533e-07\n",
      "(alphaRest, pVisits)               -6.521079e-08  7.230606e-07\n",
      "(alphaRest, propSocialVisits)      -1.680056e-07  7.174686e-07\n",
      "(alphaRest, locPerSGCount)         -1.088099e-07  7.247221e-07\n",
      "(alphaAmp, alphaShift)              1.506533e-01  6.170309e-02\n",
      "(alphaAmp, infTicksCount)           1.547023e-03  5.683743e-02\n",
      "(alphaAmp, avgVisitsCount)          2.386363e-03  5.823818e-02\n",
      "(alphaAmp, pVisits)                -1.018152e-03  5.847999e-02\n",
      "(alphaAmp, propSocialVisits)       -9.008896e-04  6.019852e-02\n",
      "(alphaAmp, locPerSGCount)           2.166247e-03  5.849035e-02\n",
      "(alphaShift, infTicksCount)         7.667253e-04  9.056147e-02\n",
      "(alphaShift, avgVisitsCount)        1.163281e-03  8.476618e-02\n",
      "(alphaShift, pVisits)              -4.201198e-04  8.556532e-02\n",
      "(alphaShift, propSocialVisits)      7.326561e-03  8.743586e-02\n",
      "(alphaShift, locPerSGCount)         1.491241e-03  8.588227e-02\n",
      "(infTicksCount, avgVisitsCount)     1.434616e-03  4.079302e-02\n",
      "(infTicksCount, pVisits)            1.799411e-03  4.143546e-02\n",
      "(infTicksCount, propSocialVisits)   6.203197e-03  4.155198e-02\n",
      "(infTicksCount, locPerSGCount)     -1.092911e-04  4.122329e-02\n",
      "(avgVisitsCount, pVisits)           1.893795e-07  3.678204e-07\n",
      "(avgVisitsCount, propSocialVisits)  1.924494e-07  3.677963e-07\n",
      "(avgVisitsCount, locPerSGCount)     1.898559e-07  3.670368e-07\n",
      "(pVisits, propSocialVisits)        -1.013957e-03  1.057332e-02\n",
      "(pVisits, locPerSGCount)           -1.061170e-03  1.006094e-02\n",
      "(propSocialVisits, locPerSGCount)   5.622789e-04  6.938049e-02\n"
     ]
    }
   ],
   "source": [
    "# Define a subset of the parameter ranges\n",
    "param_ranges = {\n",
    "    'alphaRest': (0.015),      # fix average infectivity to 0.015\n",
    "    'alphaAmp': (0, 1),\n",
    "    'alphaShift': (0, 1),\n",
    "    'infTicksCount': (4, 6),\n",
    "    'avgVisitsCount': (2),     # fix average mobility to 2\n",
    "    'pVisits': (0.05, 0.95),\n",
    "    'propSocialVisits': (0, 1),\n",
    "    'locPerSGCount': (1, 20)\n",
    "}\n",
    "\n",
    "# Perform sensitivity analysis over this subdomain\n",
    "sa = myGP.sensitivity_analysis(\n",
    "    pow2sampleSize=10, \n",
    "    param_ranges=param_ranges, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions with the GP\n",
    "\n",
    "### 5.1. Predicting model outputs for Latin Hypercube Sampled points\n",
    "\n",
    "\n",
    "1. **Latin Hypercube Sampling (LHS)**\n",
    "\n",
    "   * `LatinDesign(PARAM_RANGES).get_samples(10000)` generates 10,000 candidate points that evenly explore the input space.\n",
    "\n",
    "2. **Reformatting for the GP model**\n",
    "\n",
    "   * GP models require PyTorch tensors, so we convert the numpy array using `torch.from_numpy(...).float().contiguous()`.\n",
    "\n",
    "3. **Predictions with the GP**\n",
    "\n",
    "   * `predict_ys(parsed_data=res)` evaluates the GP at each candidate point.\n",
    "   * Returns three tensors:\n",
    "\n",
    "     * `predictions`: mean predicted outputs.\n",
    "     * `lower` and `upper`: confidence intervals for each prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predicted value: 0.530\n"
     ]
    }
   ],
   "source": [
    "candidates = LatinDesign(PARAM_RANGES).get_samples(10000) #obtain LHS \n",
    "res = torch.from_numpy(candidates).float().contiguous() #reformat data\n",
    "predictions, lower, upper = myGP.predict_ys(parsed_data = res) #predicting model outputs for LHS points\n",
    "\n",
    "print(f\"Mean predicted value: {predictions.mean().item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2. Predicting model outputs for test data\n",
    "\n",
    "1. `pd.read_csv(PATH_TEST, sep='\\t')` loads the test dataset containing observed outputs from the individual-based model.\n",
    "2. `myGP.predict(test_data=PATH_TEST)` predicts outputs for the same inputs.\n",
    "3. We extract the observed values for the current model type (`maxIncidence`, `epidemicSize`, etc.).\n",
    "4. A quick comparison DataFrame shows observed vs predicted values for the first few test points.\n",
    "5. Summary statistics (mean values) give a quick check of prediction accuracy before formal metrics like RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   simRound          10000 non-null  float64\n",
      " 1   simID             10000 non-null  float64\n",
      " 2   alphaRest         10000 non-null  float64\n",
      " 3   alphaAmp          10000 non-null  float64\n",
      " 4   alphaShift        10000 non-null  float64\n",
      " 5   infTicksCounts    10000 non-null  float64\n",
      " 6   avgVisitsCounts   10000 non-null  float64\n",
      " 7   pVisits           10000 non-null  float64\n",
      " 8   propSocialVisits  10000 non-null  float64\n",
      " 9   locPerSGCount     10000 non-null  float64\n",
      " 10  maxIncidence      10000 non-null  float64\n",
      " 11  epidemicSize      10000 non-null  float64\n",
      " 12  duration          10000 non-null  float64\n",
      " 13  sd_maxIncidence   10000 non-null  float64\n",
      " 14  sd_epidemicSize   10000 non-null  float64\n",
      " 15  sd_duration       10000 non-null  float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 1.2 MB\n",
      "   Observed  Predicted\n",
      "0  0.560750   0.568712\n",
      "1  0.204179   0.196448\n",
      "2  0.788018   0.784931\n",
      "3  0.773855   0.760501\n",
      "4  0.929093   0.920722\n",
      "\n",
      "Prediction summary:\n",
      "Mean observed value: 0.618\n",
      "Mean predicted value: 0.607\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset (observed values)\n",
    "test = pd.read_csv(PATH_TEST, sep='\\t')\n",
    "test.info()  # Check the structure and number of rows/columns\n",
    "\n",
    "# Predict outputs using the GP model\n",
    "predicted_mean, lower, upper = myGP.predict(test_data=PATH_TEST)\n",
    "\n",
    "# Extract the observed values for the same model type\n",
    "y_id = getColumnIndex(myGP.model_type)\n",
    "observed = test.iloc[:, y_id].values\n",
    "\n",
    "# Compare observed vs predicted\n",
    "comparison = pd.DataFrame({\n",
    "    'Observed': observed,\n",
    "    'Predicted': predicted_mean.numpy()\n",
    "})\n",
    "print(comparison.head())  # show first few rows\n",
    "\n",
    "print(\"\\nPrediction summary:\")\n",
    "print(f\"Mean observed value: {observed.mean():.3f}\")\n",
    "print(f\"Mean predicted value: {predicted_mean.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b1611",
   "metadata": {},
   "source": [
    "## 6. Sampling additional points based on GP predictions\n",
    "\n",
    "\n",
    "1. **Latin Hypercube Sampling (LHS)**\n",
    "\n",
    "   * `LatinDesign(PARAM_RANGES).get_samples(100000)` generates 100,000 candidate points evenly distributed across the input space.\n",
    "\n",
    "2. **GP-based sampling of points**\n",
    "\n",
    "   * `myGP.samplePoints(...)` selects `N=100` points from the candidates.\n",
    "   * `p=0.5` means that 50% of the selected points are weighted by predicted outputs (i.e., policy 2), and the remaining 50% (1-p) are sampled based on prediction uncertainty (i.e., policy 1).\n",
    "   * This approach focuses sampling on regions where the GP is most uncertain, which can be useful for active learning\n",
    "\n",
    "3. **Result**\n",
    "\n",
    "   * `candidates[id,]` shows the 100 points selected for further evaluation or simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.7065550e-02 1.0152500e-01 3.0255500e-01 4.3884300e+00 1.0260200e+00\n",
      "  9.1119650e-01 7.4299500e-01 2.0513650e+00]\n",
      " [1.4457450e-02 2.8037500e-01 7.2828500e-01 4.7442700e+00 4.1023800e+00\n",
      "  4.3992050e-01 7.7506500e-01 6.5680450e+00]\n",
      " [2.2298850e-02 9.8111500e-01 8.3368500e-01 5.3509100e+00 3.1892200e+00\n",
      "  3.1313750e-01 9.9070500e-01 1.3425715e+01]\n",
      " [1.1933250e-02 7.8837500e-01 5.4135000e-02 5.0783700e+00 4.8741000e+00\n",
      "  9.4028450e-01 7.8372500e-01 6.4266850e+00]\n",
      " [1.7198850e-02 4.1352500e-01 7.4141500e-01 4.3611500e+00 4.8309400e+00\n",
      "  2.8495850e-01 9.2865500e-01 1.5833950e+00]\n",
      " [2.2937550e-02 9.9353500e-01 8.4858500e-01 5.0419100e+00 3.0187000e+00\n",
      "  4.1078750e-01 5.2321500e-01 1.9828905e+01]\n",
      " [2.4753150e-02 5.3258500e-01 9.2792500e-01 4.1244500e+00 2.9831800e+00\n",
      "  1.6923650e-01 1.9439500e-01 7.4545850e+00]\n",
      " [9.5626500e-03 9.5660500e-01 3.5745500e-01 5.0351700e+00 2.5010200e+00\n",
      "  7.4754500e-02 2.0913500e-01 7.1274050e+00]\n",
      " [4.3395000e-04 2.8523500e-01 4.3990500e-01 4.0386300e+00 4.3889000e+00\n",
      "  4.3165850e-01 6.8151500e-01 1.8306055e+01]\n",
      " [8.2483500e-03 9.1381500e-01 3.2531500e-01 4.8050100e+00 3.6691400e+00\n",
      "  3.8506550e-01 4.7201500e-01 1.6561665e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a large set of candidate points using Latin Hypercube Sampling (LHS)\n",
    "candidates = LatinDesign(PARAM_RANGES).get_samples(100000)  # 100,000 samples\n",
    "\n",
    "# Use the GP to sample 100 points from the candidate set\n",
    "# 'p' controls the proportion of points weighted by predicted output uncertainty\n",
    "id = myGP.samplePoints(candidates=candidates, N=100, p=0.5)\n",
    "\n",
    "selected_points = candidates[id,]\n",
    "print(selected_points[:10,]) #display first few selected points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp_emulator_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
